{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This tutorial shows how a H2O [Generalized Linear Model](https://en.wikipedia.org/wiki/Generalized_linear_model) model can be used to do supervised classification. This tutorial covers usage of H2O from Python. An R version of this tutorial will be available as well in a separate document. This file is available in plain R, plain Python and iPython Notebook formats. More examples and explanations can be found in our [H2O Generalized Linear Modeling booklet](http://h2o.ai/resources/) and on our [H2O Github Repository](http://github.com/h2oai/h2o-3/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H2O Python Module\n",
    "\n",
    "Load the H2O Python module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h2o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start H2O\n",
    "Start up a 1-node H2O cloud on your local machine, and allow it to use all CPU cores and up to 2GB of memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "No instance found at ip and port: localhost:54321. Trying to start local jar...\n",
      "\n",
      "\n",
      "JVM stdout: c:\\users\\kevin\\appdata\\local\\temp\\tmp1d3z8d\\h2o_Kevin_started_from_python.out\n",
      "JVM stderr: c:\\users\\kevin\\appdata\\local\\temp\\tmplo27xm\\h2o_Kevin_started_from_python.err\n",
      "Using ice_root: c:\\users\\kevin\\appdata\\local\\temp\\tmpxkbqio\n",
      "\n",
      "\n",
      "Java Version: java version \"1.7.0_79\"\n",
      "Java(TM) SE Runtime Environment (build 1.7.0_79-b15)\n",
      "Java HotSpot(TM) 64-Bit Server VM (build 24.79-b02, mixed mode)\n",
      "\n",
      "\n",
      "Starting H2O JVM and connecting: . Connection successful!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime: </td>\n",
       "<td>1 seconds 716 milliseconds </td></tr>\n",
       "<tr><td>H2O cluster version: </td>\n",
       "<td>3.7.0.3248</td></tr>\n",
       "<tr><td>H2O cluster name: </td>\n",
       "<td>H2O_started_from_python</td></tr>\n",
       "<tr><td>H2O cluster total nodes: </td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster total memory: </td>\n",
       "<td>1.78 GB</td></tr>\n",
       "<tr><td>H2O cluster total cores: </td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores: </td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster healthy: </td>\n",
       "<td>True</td></tr>\n",
       "<tr><td>H2O Connection ip: </td>\n",
       "<td>127.0.0.1</td></tr>\n",
       "<tr><td>H2O Connection port: </td>\n",
       "<td>54321</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  --------------------------\n",
       "H2O cluster uptime:         1 seconds 716 milliseconds\n",
       "H2O cluster version:        3.7.0.3248\n",
       "H2O cluster name:           H2O_started_from_python\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster total memory:   1.78 GB\n",
       "H2O cluster total cores:    8\n",
       "H2O cluster allowed cores:  8\n",
       "H2O cluster healthy:        True\n",
       "H2O Connection ip:          127.0.0.1\n",
       "H2O Connection port:        54321\n",
       "--------------------------  --------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init(max_mem_size_GB = 2)            #uses all cores by default\n",
    "h2o.remove_all()                          #clean slate, in case cluster was already running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more about the h2o package itself, we can use Python's builtin help() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "help(h2o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "help() can be used on H2O functions and models. Jupyter's builtin shift-tab functionality also works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class H2OGeneralizedLinearEstimator in module h2o.estimators.glm:\n",
      "\n",
      "class H2OGeneralizedLinearEstimator(h2o.estimators.estimator_base.H2OEstimator)\n",
      " |  Method resolution order:\n",
      " |      H2OGeneralizedLinearEstimator\n",
      " |      h2o.estimators.estimator_base.H2OEstimator\n",
      " |      h2o.model.model_base.ModelBase\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, model_id=None, max_iterations=None, beta_epsilon=None, solver=None, standardize=None, family=None, link=None, tweedie_variance_power=None, tweedie_link_power=None, alpha=None, prior=None, lambda_search=None, nlambdas=None, lambda_min_ratio=None, beta_constraints=None, nfolds=None, fold_assignment=None, keep_cross_validation_predictions=None, intercept=None, Lambda=None, max_active_predictors=None, checkpoint=None)\n",
      " |      Build a Generalized Linear Model\n",
      " |      Fit a generalized linear model, specified by a response variable, a set of predictors,\n",
      " |      and a description of the error distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      model_id : str, optional\n",
      " |        The unique id assigned to the resulting model. If none is given, an id will\n",
      " |        automatically be generated.\n",
      " |      max_iterations : int\n",
      " |        A non-negative integer specifying the maximum number of iterations.\n",
      " |      beta_epsilon : int\n",
      " |        A non-negative number specifying the magnitude of the maximum difference between\n",
      " |        the coefficient estimates from successive iterations. Defines the convergence\n",
      " |        criterion.\n",
      " |      solver : str\n",
      " |        A character string specifying the solver used: IRLSM (supports more features),\n",
      " |        L_BFGS (scales better for datasets with many columns)\n",
      " |      standardize : bool\n",
      " |        Indicates whether the numeric predictors should be standardized to have a mean of\n",
      " |        0 and a variance of 1 prior to training the models.\n",
      " |      family : str\n",
      " |        A character string specifying the distribution of the model:\n",
      " |       gaussian, binomial, poisson, gamma, tweedie.\n",
      " |      link : str\n",
      " |        A character string specifying the link function.\n",
      " |        The default is the canonical link for the family.\n",
      " |        The supported links for each of the family specifications are:\n",
      " |            \"gaussian\": \"identity\", \"log\", \"inverse\"\n",
      " |            \"binomial\": \"logit\", \"log\"\n",
      " |            \"poisson\": \"log\", \"identity\"\n",
      " |            \"gamma\": \"inverse\", \"log\", \"identity\"\n",
      " |            \"tweedie\": \"tweedie\"\n",
      " |      \n",
      " |      tweedie_variance_power : int\n",
      " |        numeric specifying the power for the variance function when family = \"tweedie\".\n",
      " |      tweedie_link_power : int\n",
      " |        A numeric specifying the power for the link function when family = \"tweedie\".\n",
      " |      alpha : float\n",
      " |        A numeric in [0, 1] specifying the elastic-net mixing parameter.\n",
      " |      \n",
      " |        The elastic-net penalty is defined to be:\n",
      " |        eqn{P(\u0007lphaeta) = (1-\u0007lpha)/2|eta||_2^2 +\n",
      " |        \u0007lpha|eta||_1 = \\sum_j [(1-\u0007lpha)/2eta_j^2 + \u0007lphaeta_j|],\n",
      " |        making alpha = 1 the lasso penalty and alpha = 0 the ridge penalty.\n",
      " |      \n",
      " |      Lambda : float\n",
      " |        A non-negative shrinkage parameter for the elastic-net, which multiplies\n",
      " |        \\eqn{P(\u0007lphaeta) in the objective function.\n",
      " |        When Lambda = 0, no elastic-net penalty is applied and ordinary generalized linear\n",
      " |        models are fit.\n",
      " |      prior : float, optional\n",
      " |        A numeric specifying the prior probability of class 1 in the response when\n",
      " |        family = \"binomial\". The default prior is the observational frequency of class 1.\n",
      " |      lambda_search : bool\n",
      " |        A logical value indicating whether to conduct a search over the space of lambda\n",
      " |        values starting from the lambda max, given lambda is interpreted as lambda minself.\n",
      " |      nlambdas : int\n",
      " |        The number of lambda values to use when lambda_search = TRUE.\n",
      " |      lambda_min_ratio : float\n",
      " |        Smallest value for lambda as a fraction of lambda.max. By default if the number of\n",
      " |        observations is greater than the the number of variables then\n",
      " |        lambda_min_ratio = 0.0001; if the number of observations is less than the number\n",
      " |        of variables then lambda_min_ratio = 0.01.\n",
      " |      beta_constraints : H2OFrame\n",
      " |        A data.frame or H2OParsedData object with the columns\n",
      " |        [\"names\", \"lower_bounds\", \"upper_bounds\", \"beta_given\"],\n",
      " |        where each row corresponds to a predictor in the GLM.\n",
      " |        \"names\" contains the predictor names, \"lower\"/\"upper_bounds\",\n",
      " |        are the lower and upper bounds of beta, and \"beta_given\" is some supplied starting\n",
      " |        values.\n",
      " |      nfolds : int, optional\n",
      " |        Number of folds for cross-validation. If nfolds >= 2, then validation must\n",
      " |        remain empty.\n",
      " |      fold_assignment : str\n",
      " |        Cross-validation fold assignment scheme, if fold_column is not specified Must be\n",
      " |        \"AUTO\", \"Random\" or \"Modulo\"\n",
      " |      keep_cross_validation_predictions : bool\n",
      " |        Whether to keep the predictions of the cross-validation models\n",
      " |      intercept : bool\n",
      " |        Logical, include constant term (intercept) in the model\n",
      " |      max_active_predictors : int, optional\n",
      " |        Convergence criteria for number of predictors when using L1 penalty.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |        A subclass of ModelBase is returned. The specific subclass depends on the machine\n",
      " |        learning task at hand (if it's binomial classification, then an H2OBinomialModel\n",
      " |        is returned, if it's regression then a H2ORegressionModel is returned). The default\n",
      " |        print-out of the models is shown, but further GLM-specifc information can be\n",
      " |        queried out of the object. Upon completion of the GLM, the resulting object has\n",
      " |        coefficients, normalized coefficients, residual/null deviance, aic, and a host of\n",
      " |        model metrics including MSE, AUC (for logistic regression), degrees of freedom, and\n",
      " |        confusion matrices.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  Lambda\n",
      " |  \n",
      " |  alpha\n",
      " |  \n",
      " |  beta_constraints\n",
      " |  \n",
      " |  beta_epsilon\n",
      " |  \n",
      " |  checkpoint\n",
      " |  \n",
      " |  family\n",
      " |  \n",
      " |  fold_assignment\n",
      " |  \n",
      " |  intercept\n",
      " |  \n",
      " |  keep_cross_validation_predictions\n",
      " |  \n",
      " |  lambda_min_ratio\n",
      " |  \n",
      " |  lambda_search\n",
      " |  \n",
      " |  link\n",
      " |  \n",
      " |  max_active_predictors\n",
      " |  \n",
      " |  max_iterations\n",
      " |  \n",
      " |  nfolds\n",
      " |  \n",
      " |  nlambdas\n",
      " |  \n",
      " |  prior\n",
      " |  \n",
      " |  solver\n",
      " |  \n",
      " |  standardize\n",
      " |  \n",
      " |  tweedie_link_power\n",
      " |  \n",
      " |  tweedie_variance_power\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h2o.estimators.estimator_base.H2OEstimator:\n",
      " |  \n",
      " |  build_model(self, algo_params)\n",
      " |  \n",
      " |  fit(self, X, y=None, **params)\n",
      " |      Fit an H2O model as part of a scikit-learn pipeline or grid search.\n",
      " |      \n",
      " |      A warning will be issued if a caller other than sklearn attempts to use this method.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |        X : H2OFrame\n",
      " |          An H2OFrame consisting of the predictor variables.\n",
      " |        y : H2OFrame, optional\n",
      " |          An H2OFrame consisting of the response variable.\n",
      " |        params : optional\n",
      " |          Extra arguments.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |        The current instance of H2OEstimator for method chaining.\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Useful method for obtaining parameters for this estimator. Used primarily for\n",
      " |      sklearn Pipelines and sklearn grid search.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |        deep : bool, optional\n",
      " |          If True, return parameters of all sub-objects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |        A dict of parameters\n",
      " |  \n",
      " |  join(self)\n",
      " |  \n",
      " |  set_params(self, **parms)\n",
      " |      Used by sklearn for updating parameters during grid search.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |        parms : dict\n",
      " |          A dictionary of parameters that will be set on this model.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |        Returns self, the current estimator object with the parameters all set as desired.\n",
      " |  \n",
      " |  start(self, x, y=None, training_frame=None, offset_column=None, fold_column=None, weights_column=None, validation_frame=None, **params)\n",
      " |      Asynchronous model build by specifying the predictor columns, response column, and any\n",
      " |      additional frame-specific values.\n",
      " |      \n",
      " |      To block for results, call join.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |        x : list\n",
      " |          A list of column names or indices indicating the predictor columns.\n",
      " |        y : str\n",
      " |          An index or a column name indicating the response column.\n",
      " |        training_frame : H2OFrame\n",
      " |          The H2OFrame having the columns indicated by x and y (as well as any\n",
      " |          additional columns specified by fold, offset, and weights).\n",
      " |        offset_column : str, optional\n",
      " |          The name or index of the column in training_frame that holds the offsets.\n",
      " |        fold_column : str, optional\n",
      " |          The name or index of the column in training_frame that holds the per-row fold\n",
      " |          assignments.\n",
      " |        weights_column : str, optional\n",
      " |          The name or index of the column in training_frame that holds the per-row weights.\n",
      " |        validation_frame : H2OFrame, optional\n",
      " |          H2OFrame with validation data to be scored on while training.\n",
      " |  \n",
      " |  train(self, x, y=None, training_frame=None, offset_column=None, fold_column=None, weights_column=None, validation_frame=None, **params)\n",
      " |      Train the H2O model by specifying the predictor columns, response column, and any\n",
      " |      additional frame-specific values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |        x : list\n",
      " |          A list of column names or indices indicating the predictor columns.\n",
      " |        y : str\n",
      " |          An index or a column name indicating the response column.\n",
      " |        training_frame : H2OFrame\n",
      " |          The H2OFrame having the columns indicated by x and y (as well as any\n",
      " |          additional columns specified by fold, offset, and weights).\n",
      " |        offset_column : str, optional\n",
      " |          The name or index of the column in training_frame that holds the offsets.\n",
      " |        fold_column : str, optional\n",
      " |          The name or index of the column in training_frame that holds the per-row fold\n",
      " |          assignments.\n",
      " |        weights_column : str, optional\n",
      " |          The name or index of the column in training_frame that holds the per-row weights.\n",
      " |        validation_frame : H2OFrame, optional\n",
      " |          H2OFrame with validation data to be scored on while training.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from h2o.estimators.estimator_base.H2OEstimator:\n",
      " |  \n",
      " |  mixin(obj, cls)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h2o.model.model_base.ModelBase:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |  \n",
      " |  aic(self, train=False, valid=False, xval=False)\n",
      " |      Get the AIC(s).\n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\", \"valid\",\n",
      " |      and \"xval\"\n",
      " |      \n",
      " |      :param train: If train is True, then return the AIC value for the training data.\n",
      " |      :param valid: If valid is True, then return the AIC value for the validation data.\n",
      " |      :param xval:  If xval is True, then return the AIC value for the validation data.\n",
      " |      :return: The AIC.\n",
      " |  \n",
      " |  auc(self, train=False, valid=False, xval=False)\n",
      " |      Get the AUC(s).\n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\", \"valid\",\n",
      " |      and \"xval\"\n",
      " |      \n",
      " |      :param train: If train is True, then return the AUC value for the training data.\n",
      " |      :param valid: If valid is True, then return the AUC value for the validation data.\n",
      " |      :param xval:  If xval is True, then return the AUC value for the validation data.\n",
      " |      :return: The AUC.\n",
      " |  \n",
      " |  biases(self, vector_id=0)\n",
      " |      Return the frame for the respective bias vector\n",
      " |      :param: vector_id: an integer, ranging from 0 to number of layers, that specifies the bias vector to return.\n",
      " |      :return: an H2OFrame which represents the bias vector identified by vector_id\n",
      " |  \n",
      " |  catoffsets(self)\n",
      " |      Categorical offsets for one-hot encoding\n",
      " |  \n",
      " |  coef(self)\n",
      " |      :return: Return the coefficients for this model.\n",
      " |  \n",
      " |  coef_norm(self)\n",
      " |      :return: Return the normalized coefficients\n",
      " |  \n",
      " |  deepfeatures(self, test_data, layer)\n",
      " |      Return hidden layer details\n",
      " |      \n",
      " |      :param test_data: Data to create a feature space on\n",
      " |      :param layer: 0 index hidden layer\n",
      " |  \n",
      " |  download_pojo(self, path='')\n",
      " |      Download the POJO for this model to the directory specified by path (no trailing slash!).\n",
      " |      If path is \"\", then dump to screen.\n",
      " |      :param model: Retrieve this model's scoring POJO.\n",
      " |      :param path:  An absolute path to the directory where POJO should be saved.\n",
      " |      :return: None\n",
      " |  \n",
      " |  get_xval_models(self, key=None)\n",
      " |      Return a Model object.\n",
      " |      \n",
      " |      :param key: If None, return all cross-validated models; otherwise return the model that key points to.\n",
      " |      :return: A model or list of models.\n",
      " |  \n",
      " |  giniCoef(self, train=False, valid=False, xval=False)\n",
      " |      Get the Gini Coefficient(s).\n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\", \"valid\",\n",
      " |      and \"xval\"\n",
      " |      \n",
      " |      :param train: If train is True, then return the Gini Coefficient value for the training data.\n",
      " |      :param valid: If valid is True, then return the Gini Coefficient value for the validation data.\n",
      " |      :param xval:  If xval is True, then return the Gini Coefficient value for the cross validation data.\n",
      " |      :return: The Gini Coefficient for this binomial model.\n",
      " |  \n",
      " |  is_cross_validated(self)\n",
      " |      :return:  True if the model was cross-validated.\n",
      " |  \n",
      " |  logloss(self, train=False, valid=False, xval=False)\n",
      " |      Get the Log Loss(s).\n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\", \"valid\",\n",
      " |      and \"xval\"\n",
      " |      \n",
      " |      :param train: If train is True, then return the Log Loss value for the training data.\n",
      " |      :param valid: If valid is True, then return the Log Loss value for the validation data.\n",
      " |      :param xval:  If xval is True, then return the Log Loss value for the cross validation data.\n",
      " |      :return: The Log Loss for this binomial model.\n",
      " |  \n",
      " |  mean_residual_deviance(self, train=False, valid=False, xval=False)\n",
      " |      Get the Mean Residual Deviances(s).\n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\", \"valid\",\n",
      " |      and \"xval\"\n",
      " |      \n",
      " |      :param train: If train is True, then return the Mean Residual Deviance value for the training data.\n",
      " |      :param valid: If valid is True, then return the Mean Residual Deviance value for the validation data.\n",
      " |      :param xval:  If xval is True, then return the Mean Residual Deviance value for the cross validation data.\n",
      " |      :return: The Mean Residual Deviance for this regression model.\n",
      " |  \n",
      " |  model_performance(self, test_data=None, train=False, valid=False)\n",
      " |      Generate model metrics for this model on test_data.\n",
      " |      \n",
      " |      :param test_data: Data set for which model metrics shall be computed against. Both train and valid arguments are ignored if test_data is not None.\n",
      " |      :param train: Report the training metrics for the model. If the test_data is the training data, the training metrics are returned.\n",
      " |      :param valid: Report the validation metrics for the model. If train and valid are True, then it defaults to True.\n",
      " |      :return: An object of class H2OModelMetrics.\n",
      " |  \n",
      " |  mse(self, train=False, valid=False, xval=False)\n",
      " |      Get the MSE(s).\n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\", \"valid\",\n",
      " |      and \"xval\"\n",
      " |      \n",
      " |      :param train: If train is True, then return the MSE value for the training data.\n",
      " |      :param valid: If valid is True, then return the MSE value for the validation data.\n",
      " |      :param xval:  If xval is True, then return the MSE value for the cross validation data.\n",
      " |      :return: The MSE for this regression model.\n",
      " |  \n",
      " |  normmul(self)\n",
      " |      Normalization/Standardization multipliers for numeric predictors\n",
      " |  \n",
      " |  normsub(self)\n",
      " |      Normalization/Standardization offsets for numeric predictors\n",
      " |  \n",
      " |  null_degrees_of_freedom(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the null degress of freedom if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param train: Get the null dof for the training set. If both train and valid are False, then train is selected by default.\n",
      " |      :param valid: Get the null dof for the validation set. If both train and valid are True, then train is selected by default.\n",
      " |      :return: Return the null dof, or None if it is not present.\n",
      " |  \n",
      " |  null_deviance(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the null deviance if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param:  train Get the null deviance for the training set. If both train and valid are False, then train is selected by default.\n",
      " |      :param:  valid Get the null deviance for the validation set. If both train and valid are True, then train is selected by default.\n",
      " |      :return: Return the null deviance, or None if it is not present.\n",
      " |  \n",
      " |  pprint_coef(self)\n",
      " |      Pretty print the coefficents table (includes normalized coefficients)\n",
      " |      :return: None\n",
      " |  \n",
      " |  predict(self, test_data)\n",
      " |      Predict on a dataset.\n",
      " |      \n",
      " |      :param test_data: Data to be predicted on.\n",
      " |      :return: A new H2OFrame filled with predictions.\n",
      " |  \n",
      " |  r2(self, train=False, valid=False, xval=False)\n",
      " |      Return the R^2 for this regression model.\n",
      " |      \n",
      " |      The R^2 value is defined to be 1 - MSE/var,\n",
      " |      where var is computed as sigma*sigma.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\", \"valid\",\n",
      " |      and \"xval\"\n",
      " |      \n",
      " |      :param train: If train is True, then return the R^2 value for the training data.\n",
      " |      :param valid: If valid is True, then return the R^2 value for the validation data.\n",
      " |      :param xval:  If xval is True, then return the R^2 value for the cross validation data.\n",
      " |      :return: The R^2 for this regression model.\n",
      " |  \n",
      " |  residual_degrees_of_freedom(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the residual degress of freedom if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param train: Get the residual dof for the training set. If both train and valid are False, then train is selected by default.\n",
      " |      :param valid: Get the residual dof for the validation set. If both train and valid are True, then train is selected by default.\n",
      " |      :return: Return the residual dof, or None if it is not present.\n",
      " |  \n",
      " |  residual_deviance(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the residual deviance if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param train: Get the residual deviance for the training set. If both train and valid are False, then train is selected by default.\n",
      " |      :param valid: Get the residual deviance for the validation set. If both train and valid are True, then train is selected by default.\n",
      " |      :return: Return the residual deviance, or None if it is not present.\n",
      " |  \n",
      " |  respmul(self)\n",
      " |      Normalization/Standardization multipliers for numeric response\n",
      " |  \n",
      " |  respsub(self)\n",
      " |      Normalization/Standardization offsets for numeric response\n",
      " |  \n",
      " |  score_history(self)\n",
      " |      Retrieve Model Score History\n",
      " |      :return: the score history (H2OTwoDimTable)\n",
      " |  \n",
      " |  show(self)\n",
      " |      Print innards of model, without regards to type\n",
      " |      \n",
      " |      :return: None\n",
      " |  \n",
      " |  summary(self)\n",
      " |      Print a detailed summary of the model.\n",
      " |      \n",
      " |      :return:\n",
      " |  \n",
      " |  varimp(self, return_list=False)\n",
      " |      Pretty print the variable importances, or return them in a list\n",
      " |      :param return_list: if True, then return the variable importances in an list (ordered from most important to least\n",
      " |      important). Each entry in the list is a 4-tuple of (variable, relative_importance, scaled_importance, percentage).\n",
      " |      :return: None or ordered list\n",
      " |  \n",
      " |  weights(self, matrix_id=0)\n",
      " |      Return the frame for the respective weight matrix\n",
      " |      :param: matrix_id: an integer, ranging from 0 to number of layers, that specifies the weight matrix to return.\n",
      " |      :return: an H2OFrame which represents the weight matrix identified by matrix_id\n",
      " |  \n",
      " |  xval_keys(self)\n",
      " |      :return: The model keys for the cross-validated model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from h2o.model.model_base.ModelBase:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  full_parameters\n",
      " |      Get the full specification of all parameters.\n",
      " |      \n",
      " |      :return: a dictionary of parameters used to build this model.\n",
      " |  \n",
      " |  model_id\n",
      " |      :return: Retrieve this model's identifier.\n",
      " |  \n",
      " |  params\n",
      " |      Get the parameters and the actual/default values only.\n",
      " |      \n",
      " |      :return: A dictionary of parameters used to build this model.\n",
      " |  \n",
      " |  xvals\n",
      " |      Return a list of the cross-validated models.\n",
      " |      \n",
      " |      :return: A list of models\n",
      "\n",
      "Help on function import_file in module h2o.h2o:\n",
      "\n",
      "import_file(path=None, destination_frame='', parse=True, header=(-1, 0, 1), sep='', col_names=None, col_types=None, na_strings=None)\n",
      "    Have H2O import a dataset into memory. The path to the data must be a valid path for\n",
      "    each node in the H2O cluster. If some node in the H2O cluster cannot see the file, then\n",
      "    an exception will be thrown by the H2O cluster.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "      path : str\n",
      "        A path specifying the location of the data to import.\n",
      "      destination_frame : str, optional\n",
      "        The unique hex key assigned to the imported file. If none is given, a key will\n",
      "        automatically be generated.\n",
      "      parse : bool, optional\n",
      "        A logical value indicating whether the file should be parsed after import.\n",
      "      header : int, optional\n",
      "       -1 means the first line is data, 0 means guess, 1 means first line is header.\n",
      "      sep : str, optional\n",
      "        The field separator character. Values on each line of the file are separated by this\n",
      "        character. If sep = \"\", the parser will automatically detect the separator.\n",
      "      col_names : list, optional\n",
      "        A list of column names for the file.\n",
      "      col_types : list or dict, optional\n",
      "        A list of types or a dictionary of column names to types to specify whether columns\n",
      "        should be forced to a certain type upon import parsing. If a list, the types for\n",
      "        elements that are None will be guessed. The possible types a column may have are:\n",
      "            \"unknown\" - this will force the column to be parsed as all NA\n",
      "            \"uuid\"    - the values in the column must be true UUID or will be parsed as NA\n",
      "            \"string\"  - force the column to be parsed as a string\n",
      "            \"numeric\" - force the column to be parsed as numeric. H2O will handle the\n",
      "                        compression of the numeric data in the optimal manner.\n",
      "            \"enum\"    - force the column to be parsed as a categorical column.\n",
      "            \"time\"    - force the column to be parsed as a time column. H2O will attempt to\n",
      "                        parse the following list of date time formats.\n",
      "                          date:\n",
      "                            \"yyyy-MM-dd\"\n",
      "                            \"yyyy MM dd\"\n",
      "                            \"dd-MMM-yy\"\n",
      "                            \"dd MMM yy\"\n",
      "                          time:\n",
      "                            \"HH:mm:ss\"\n",
      "                            \"HH:mm:ss:SSS\"\n",
      "                            \"HH:mm:ss:SSSnnnnnn\"\n",
      "                            \"HH.mm.ss\"\n",
      "                            \"HH.mm.ss.SSS\"\n",
      "                            \"HH.mm.ss.SSSnnnnnn\"\n",
      "                        Times can also contain \"AM\" or \"PM\".\n",
      "      na_strings : list or dict, optional\n",
      "        A list of strings, or a list of lists of strings (one list per column), or a\n",
      "        dictionary of column names to strings which are to be interpreted as missing values.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "      A new H2OFrame instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n",
    "help(H2OGeneralizedLinearEstimator)\n",
    "help(h2o.import_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we use pandas DataFrames to simplify some processes later in this demo, let's import both pandas and numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##H2O GLM\n",
    "\n",
    "Generalized linear models (GLMs) are an extension of traditional linear models. They have gained popularity in statistical data analysis due to:  \n",
    "\n",
    "1. the flexibility of the model structure unifying the typical regression methods (such as linear regression and logistic regression for binary classification)  \n",
    "2. the recent availability of model-fitting software  \n",
    "3. the ability to scale well with large datasets  \n",
    "\n",
    "H2O's GLM algorithm fits generalized linear models to the data by maximizing the log-likelihood. The elastic net penalty can be used for parameter regularization. The model fitting computation is distributed, extremely fast, and scales extremely well for models with a limited number of predictors with non-zero coefficients (~ low thousands).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Getting started\n",
    "\n",
    "We begin by importing our data into H2OFrames, which operate similarly in function to pandas DataFrames but exist on the H2O cloud itself.  \n",
    "\n",
    "In this case, the H2O cluster is running on our laptops. Data files are imported by their relative locations to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "covtype_df = h2o.import_file(\"../data/covtype.full.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the full covertype dataset (581k rows, 13 columns, 10 numerical, 3 categorical) and then split the data 3 ways:  \n",
    "  \n",
    "60% for training  \n",
    "20% for validation (hyper parameter tuning)  \n",
    "20% for final testing  \n",
    "\n",
    " We will train a data set on one set and use the others to test the validity of the model by ensuring that it can predict accurately on data the model has not been shown.  \n",
    " \n",
    " The second set will be used for validation most of the time.  \n",
    " \n",
    " The third set will be withheld until the end, to ensure that our validation accuracy is consistent with data we have never seen during the iterative process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parse Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "#split the data as described above\n",
    "train, valid, test = covtype_df.split_frame([0.7, 0.15], seed=1234)\n",
    "\n",
    "#Prepare predictors and response columns\n",
    "covtype_X = covtype_df.col_names[:-1]     #last column is Cover_Type, our desired response variable \n",
    "covtype_y = covtype_df.col_names[-1]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cut_column(train_df, train, valid, test, col):\n",
    "    '''\n",
    "    Convenience function to change a column from numerical to categorical\n",
    "    We use train_df only for bucketing with histograms.\n",
    "    Uses np.histogram to generate a histogram, with the buckets forming the categories of our new categorical.\n",
    "    Picks buckets based on training data, then applies the same classification to the test and validation sets\n",
    "    \n",
    "    Assumes that train, valid, test will have the same histogram behavior.\n",
    "    '''\n",
    "    only_col= train_df[col]                            #Isolate the column in question from the training frame\n",
    "    counts, breaks = np.histogram(only_col, bins=20)   #Generate counts and breaks for our histogram\n",
    "    min_val = min(only_col)-1                          #Establish min and max values\n",
    "    max_val = max(only_col)+1\n",
    "    \n",
    "    new_b = [min_val]                                  #Redefine breaks such that each bucket has enough support\n",
    "    for i in xrange(19):\n",
    "        if counts[i] > 1000 and counts[i+1] > 1000:\n",
    "            new_b.append(breaks[i+1])\n",
    "    new_b.append(max_val)\n",
    "    \n",
    "    names = [col + '_' + str(x) for x in xrange(len(new_b)-1)]  #Generate names for buckets, these will be categorical names\n",
    "\n",
    "    train[col+\"_cut\"] = train[col].cut(breaks=new_b, labels=names)\n",
    "    valid[col+\"_cut\"] = valid[col].cut(breaks=new_b, labels=names)\n",
    "    test[col+\"_cut\"] = test[col].cut(breaks=new_b, labels=names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_features(train, valid, test):\n",
    "    '''\n",
    "    Helper function to add a specific set of features to our covertype dataset\n",
    "    '''\n",
    "    #pull train dataset into Python\n",
    "    train_df = train.as_data_frame(True)\n",
    "    \n",
    "    #Make categoricals for several columns\n",
    "    cut_column(train_df, train, valid, test, \"Elevation\")\n",
    "    cut_column(train_df, train, valid, test, \"Hillshade_Noon\")\n",
    "    cut_column(train_df, train, valid, test, \"Hillshade_9am\")\n",
    "    cut_column(train_df, train, valid, test, \"Hillshade_3pm\")\n",
    "    cut_column(train_df, train, valid, test, \"Horizontal_Distance_To_Hydrology\")\n",
    "    cut_column(train_df, train, valid, test, \"Slope\")\n",
    "    cut_column(train_df, train, valid, test, \"Horizontal_Distance_To_Roadways\")\n",
    "    cut_column(train_df, train, valid, test, \"Aspect\")\n",
    "    \n",
    "    \n",
    "    #Add interaction columns for a subset of columns\n",
    "    interaction_cols1 = [\"Elevation_cut\",\n",
    "                         \"Wilderness_Area\",\n",
    "                         \"Soil_Type\",\n",
    "                         \"Hillshade_Noon_cut\",\n",
    "                         \"Hillshade_9am_cut\",\n",
    "                         \"Hillshade_3pm_cut\",\n",
    "                         \"Horizontal_Distance_To_Hydrology_cut\",\n",
    "                         \"Slope_cut\",\n",
    "                         \"Horizontal_Distance_To_Roadways_cut\",\n",
    "                         \"Aspect_cut\"]\n",
    "\n",
    "    train_cols = train.interaction(factors=interaction_cols1,    #Generate pairwise columns\n",
    "                                   pairwise=True,\n",
    "                                   max_factors=1000,\n",
    "                                   min_occurrence=100,\n",
    "                                   destination_frame=\"itrain\")\n",
    "    valid_cols = valid.interaction(factors=interaction_cols1,\n",
    "                                   pairwise=True,\n",
    "                                   max_factors=1000,\n",
    "                                   min_occurrence=100,\n",
    "                                   destination_frame=\"ivalid\")\n",
    "    test_cols = test.interaction(factors=interaction_cols1,\n",
    "                                   pairwise=True,\n",
    "                                   max_factors=1000,\n",
    "                                   min_occurrence=100,\n",
    "                                   destination_frame=\"itest\")\n",
    "    \n",
    "    train = train.cbind(train_cols)                              #Append pairwise columns to H2OFrames\n",
    "    valid = valid.cbind(valid_cols)\n",
    "    test = test.cbind(test_cols)\n",
    "    \n",
    "    \n",
    "    #Add a three-way interaction for Hillshade\n",
    "    interaction_cols2 = [\"Hillshade_Noon_cut\",\"Hillshade_9am_cut\",\"Hillshade_3pm_cut\"]\n",
    "    \n",
    "    train_cols = train.interaction(factors=interaction_cols2,    #Generate pairwise columns\n",
    "                                   pairwise=False,\n",
    "                                   max_factors=1000,\n",
    "                                   min_occurrence=100,\n",
    "                                   destination_frame=\"itrain\")\n",
    "    valid_cols = valid.interaction(factors=interaction_cols2,\n",
    "                                   pairwise=False,\n",
    "                                   max_factors=1000,\n",
    "                                   min_occurrence=100,\n",
    "                                   destination_frame=\"ivalid\")\n",
    "    test_cols = test.interaction(factors=interaction_cols2,\n",
    "                                   pairwise=False,\n",
    "                                   max_factors=1000,\n",
    "                                   min_occurrence=100,\n",
    "                                   destination_frame=\"itest\")\n",
    "    \n",
    "    train = train.cbind(train_cols)                              #Append pairwise columns to H2OFrames\n",
    "    valid = valid.cbind(valid_cols)\n",
    "    test = test.cbind(test_cols)\n",
    "    \n",
    "    return train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interactions Progress: [##################################################] 100%\n",
      "\n",
      "Interactions Progress: [##################################################] 100%\n",
      "\n",
      "Interactions Progress: [##################################################] 100%\n",
      "\n",
      "Interactions Progress: [##################################################] 100%\n",
      "\n",
      "Interactions Progress: [##################################################] 100%\n",
      "\n",
      "Interactions Progress: [##################################################] 100%\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_v, test_v, valid_v = add_features(train, test, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "covtype_df.interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
