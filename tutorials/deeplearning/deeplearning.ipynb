{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This tutorial shows how a H2O [Deep Learning](http://en.wikipedia.org/wiki/Deep_learning) model can be used to do supervised classification and regression. This tutorial covers usage of H2O from R. A python version of this tutorial will be available as well in a separate document. This file is available in plain R, R markdown and regular markdown formats, and the plots are available as PDF files. More examples and explanations can be found in our [H2O Deep Learning booklet](http://h2o.ai/resources/) and on our [H2O Github Repository](http://github.com/h2oai/h2o-3/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H2O Python Module\n",
    "\n",
    "Load the H2O Python module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h2o\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start H2O\n",
    "Start up a 1-node H2O server on your local machine, and allow it to use all CPU cores and up to 2GB of memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h2o.init(max_mem_size_GB = 2)            #uses all cores by default\n",
    "h2o.remove_all()                          #clean slate, in case cluster was already running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `h2o.deeplearning` function fits H2O's Deep Learning models from within R.\n",
    "To learn more about the h2o package itself, we can use Python's builtin help() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(h2o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "help() can be used on H2O functions and models. Jupyter's builtin shift-tab functionality also works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from h2o.estimators.deeplearning import H2OAutoEncoderEstimator, H2ODeepLearningEstimator\n",
    "help(H2ODeepLearningEstimator)\n",
    "help(h2o.import_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##H2O Deep Learning\n",
    "While H2O Deep Learning has many parameters, it was designed to be just as easy to use as the other supervised training methods in H2O. Early stopping, automatic data standardization and handling of categorical variables and missing values and adaptive learning rates (per weight) reduce the amount of parameters the user has to specify. Often, it's just the number and sizes of hidden layers, the number of epochs and the activation function and maybe some regularization techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's have some fun first: Decision Boundaries\n",
    "We start with a small dataset representing red and black dots on a plane, arranged in the shape of two nested spirals. Then we task H2O's machine learning methods to separate the red and black dots, i.e., recognize each spiral as such by assigning each point in the plane to one of the two spirals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the nature of H2O Deep Learning (DL), H2O's tree methods (GBM/DRF) and H2O's generalized linear modeling (GLM) by plotting the decision boundary between the red and black spirals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline                        \n",
    "#IMPORT ALL THE THINGS\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from h2o.estimators.deeplearning import H2OAutoEncoderEstimator, H2ODeepLearningEstimator\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n",
    "from h2o.estimators.random_forest import H2ORandomForestEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to upload our datasets to the the H2O cluster. The data is imported into H2OFrames, which operate similarly in function to pandas DataFrames.  \n",
    "\n",
    "In this case, the cluster is running on our laptops. Data files are imported by their relative locations to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spiral = h2o.upload_file(\"../data/spiral.csv\")\n",
    "grid  = h2o.upload_file(\"../data/grid.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spiral is a simple data set consisting of two spirals of black and red dots.  \n",
    "Grid is a 201 by 201 matrix with dimensions [-1.5, 1.5] by [-1.5, 1.5].\n",
    "\n",
    "To visualize these datasets, we can pull them from H2OFrames into pandas DataFrames for easier plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spiral_df = spiral.as_data_frame(use_pandas=True)\n",
    "grid_df = grid.as_data_frame(use_pandas=True)\n",
    "grid_x, grid_y = grid_df.x.reshape(201,201), grid_df.y.reshape(201,201)\n",
    "spiral_r = spiral_df[spiral_df.color == \"Red\"]\n",
    "spiral_k = spiral_df[spiral_df.color == \"Black\"]\n",
    "\n",
    "spiral_xr, spiral_yr = spiral_r[spiral_r.columns[0]], spiral_r[spiral_r.columns[1]]\n",
    "spiral_xk, spiral_yk = spiral_k[spiral_k.columns[0]], spiral_k[spiral_k.columns[1]]\n",
    "    \n",
    "markersize_ = 7**2\n",
    "plt.figure(figsize = (5,5))\n",
    "plt.scatter(spiral_xr, spiral_yr, c = 'r', s=markersize_)\n",
    "plt.scatter(spiral_xk, spiral_yk, c = 'k', s=markersize_)\n",
    "plt.axis([-1.5, 1.5, -1.5, 1.5])\n",
    "plt.title(\"Spiral\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Model Construction\n",
    "H2O in Python is designed to be very similar in look and feel to to scikit-learn. Models are initialized individually with desired or default parameters and then trained on data.  \n",
    "\n",
    "Note that the below examples use model.train(), as opposed the traditional model.fit()\n",
    "This is because h2o-py takes the data frame AND column indices for the feature and response columns, while scikit-learn takes in feature frames.\n",
    "\n",
    "H2O supports model.fit() so that it can be incorporated into a scikit-learn pipeline, but we advise using train() in all other cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = spiral.col_names[0:2]\n",
    "y = spiral.col_names[2]\n",
    "dl_model = H2ODeepLearningEstimator(epochs=1000)\n",
    "dl_model.train(X, y, spiral)\n",
    "\n",
    "gbm_model = H2OGradientBoostingEstimator()\n",
    "gbm_model.train(X, y, spiral)\n",
    "\n",
    "drf_model = H2ORandomForestEstimator()\n",
    "drf_model.train(X, y, spiral)\n",
    "\n",
    "glm_model = H2OGeneralizedLinearEstimator(family=\"binomial\")\n",
    "glm_model.fit(spiral[X], spiral[y])                                #model.fit() example\n",
    "\n",
    "models = [dl_model, gbm_model, drf_model, glm_model]\n",
    "m_names = [\"Deep Learning\", \"Gradient Boosted Method\", \"Distributed Random Forest\", \"Generalized Linear Model\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2, figsize=(12,12))\n",
    "\n",
    "for k, subplot in enumerate(ax.flatten()):\n",
    "    subplot.scatter(spiral_xr, spiral_yr, c = 'r', s=markersize_)\n",
    "    subplot.scatter(spiral_xk, spiral_yk, c = 'k', s=markersize_)\n",
    "    subplot.axis([-1.5, 1.5, -1.5, 1.5])\n",
    "    subplot.set_title(m_names[k])\n",
    "    subplot.set_xlabel('x')\n",
    "    subplot.set_ylabel('y')\n",
    "    pred_z = models[k].predict(grid).as_data_frame(True)\n",
    "    subplot.contour(grid_x, grid_y, (pred_z['predict'] == 'Black').astype(np.int).reshape(201,201), colors='b')\n",
    "    \n",
    "# plt.subplot(224)             # the second subplot in the first figure\n",
    "# plt.plot([4, 5, 6]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cov_df = h2o.upload_file(\"../data/covtype.full.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Shutdown H2O Cluster\n",
    "Shut down the cluster now that we are done using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = spiral.col_names[0:2]\n",
    "spiral[X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
